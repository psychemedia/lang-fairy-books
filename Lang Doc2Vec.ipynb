{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be137e4a",
   "metadata": {},
   "source": [
    "# Doc2Vec Searching of Lang Database\n",
    "\n",
    "Use `gensim` and a simple `doc2vec` model trained on stories from the Lang coloured fairy books to support semantic retrieval of fairy stories.\n",
    "\n",
    "The approach can be summarised as follows:\n",
    "\n",
    "- generate a vocabulary of terms representative of the search corpus;\n",
    "- generate a vector space where each dimension is a word in the vocabulary;\n",
    "- generate a vector for each document or search phrase;\n",
    "- retrieve documents based on similarity between document vector and search phrase vector.\n",
    "\n",
    "The following recipe is inspired by [How to make a search engine on Movies Description](https://github.com/ppontisso/Text-Search-Engine-using-Doc2Vec-and-TF-IDF/blob/master/notebook.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed44785",
   "metadata": {},
   "source": [
    "## Connecting to the Database\n",
    "\n",
    "We're going to work with our Lang fairy story database, so let's set up a connection to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "477c440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite_utils import Database\n",
    "\n",
    "db_name = \"demo.db\"\n",
    "\n",
    "db = Database(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50bf266",
   "metadata": {},
   "source": [
    "Let's remind ourselves of the database structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f22cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE [books] (\n",
      "   [book] TEXT,\n",
      "   [title] TEXT,\n",
      "   [text] TEXT,\n",
      "   [last_para] TEXT,\n",
      "   [first_line] TEXT,\n",
      "   [provenance] TEXT,\n",
      "   [chapter_order] INTEGER,\n",
      "   PRIMARY KEY ([book], [title])\n",
      ");\n",
      "CREATE TABLE [books_metadata] (\n",
      "   [title] TEXT,\n",
      "   [year] INTEGER\n",
      ");\n",
      "CREATE VIRTUAL TABLE [books_fts] USING FTS5 (\n",
      "    [title], [text],\n",
      "    content=[books]\n",
      ");\n",
      "CREATE TABLE 'books_fts_data'(id INTEGER PRIMARY KEY, block BLOB);\n",
      "CREATE TABLE 'books_fts_idx'(segid, term, pgno, PRIMARY KEY(segid, term)) WITHOUT ROWID;\n",
      "CREATE TABLE 'books_fts_docsize'(id INTEGER PRIMARY KEY, sz BLOB);\n",
      "CREATE TABLE 'books_fts_config'(k PRIMARY KEY, v) WITHOUT ROWID;\n",
      "CREATE TRIGGER [books_ai] AFTER INSERT ON [books] BEGIN\n",
      "  INSERT INTO [books_fts] (rowid, [title], [text]) VALUES (new.rowid, new.[title], new.[text]);\n",
      "END;\n",
      "CREATE TRIGGER [books_ad] AFTER DELETE ON [books] BEGIN\n",
      "  INSERT INTO [books_fts] ([books_fts], rowid, [title], [text]) VALUES('delete', old.rowid, old.[title], old.[text]);\n",
      "END;\n",
      "CREATE TRIGGER [books_au] AFTER UPDATE ON [books] BEGIN\n",
      "  INSERT INTO [books_fts] ([books_fts], rowid, [title], [text]) VALUES('delete', old.rowid, old.[title], old.[text]);\n",
      "  INSERT INTO [books_fts] (rowid, [title], [text]) VALUES (new.rowid, new.[title], new.[text]);\n",
      "END;\n",
      "CREATE TABLE story_vectors \n",
      "    (tag TEXT PRIMARY KEY, vector array, book TEXT, title TEXT );\n"
     ]
    }
   ],
   "source": [
    "print(db.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ad4873",
   "metadata": {},
   "source": [
    "Recall that we can perform a full text search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1365118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hansel And Grettel\n"
     ]
    }
   ],
   "source": [
    "#q = 'king \"three sons\" gold'\n",
    "q = 'hansel witch'\n",
    "_q = f'SELECT title FROM books_fts WHERE books_fts MATCH {db.quote(q)} ;'\n",
    "\n",
    "for row in db.query(_q):\n",
    "    print(row[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f69bdd6",
   "metadata": {},
   "source": [
    "We can randomly sample a selection of rows with a query of the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db76c497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grasp All, Lose All\n",
      "The Sea King's Gift\n",
      "The Three Brothers\n",
      "The Cottager And His Cat\n",
      "The Golden Mermaid\n"
     ]
    }
   ],
   "source": [
    "# Via https://gist.github.com/alecco/9976dab8fda8256ed403054ed0a65d7b\n",
    "\n",
    "_q_random_sample = \"\"\"\n",
    "SELECT * FROM books\n",
    "WHERE rowid IN (SELECT rowid FROM books\n",
    "                WHERE title NOT LIKE \"Preface\"\n",
    "                ORDER BY random() LIMIT {});\n",
    "\"\"\"\n",
    "\n",
    "for row in db.query(_q_random_sample.format(5)):\n",
    "    print(row[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7fcdea",
   "metadata": {},
   "source": [
    "## Simple Model\n",
    "\n",
    "We could use an off-the-shelf model to process documents, or we can train our own model from our own documents so that the word vectors are aligned to our dataset. In a large corpus, we can train on a sample of documents if they are representative of the whole.\n",
    "\n",
    "If we train against the whole dataset, we can search into the dataset directly from the model. If train the model on a partial collection, then we can only compare search phrases and documents that we have generated vectors for.\n",
    "\n",
    "To create the model, it helps if we clean the documents, e.g. by decasing, and removing punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d49af8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_numeric, remove_stopwords\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Generate a cleaned, tokenised version of a text.\"\"\"\n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(),\n",
    "                      strip_tags, strip_punctuation,\n",
    "                      strip_numeric, remove_stopwords]\n",
    "    \n",
    "    return preprocess_string(text, CUSTOM_FILTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecfe1de4",
   "metadata": {},
   "source": [
    "Apply the cleaning function to the text on the way in to creating the training corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8ecb662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['time', 'certain', 'country', 'lived', 'king'],\n",
       " 'The Blue Fairy Book::The Bronze Ring',\n",
       " 'The Bronze Ring')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_corpus = db.query(_q_random_sample.format(9999))\n",
    "\n",
    "sample_docs = [(clean_text(r['text']),\n",
    "               f\"{r['book']}::{r['title']}\", #create a unique tag\n",
    "               r['title'])\n",
    "               for r in sample_corpus]\n",
    "\n",
    "# For the first doc, preview the first 5 cleaned words and title\n",
    "sample_docs[0][0][:5], sample_docs[0][1], sample_docs[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920280f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gensim model needs named tuples\n",
    "# including at least a words and tags dimension\n",
    "# Naively we can just use a document index count as the tag\n",
    "from collections import namedtuple\n",
    "\n",
    "StoryDoc = namedtuple('StoryDoc',\n",
    "                      'words tags title')\n",
    "\n",
    "sample_docs_training = []\n",
    "\n",
    "for i, sample_doc in enumerate(sample_docs):\n",
    "    sample_docs_training.append(StoryDoc(sample_doc[0],\n",
    "                                         [sample_doc[1]],\n",
    "                                         sample_doc[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45268fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# Define the parameters for building the model.\n",
    "# We can also pass a list of documents\n",
    "# via the first \"documents\" parameter\n",
    "# and the model will be trained against those.\n",
    "# Alternatively, create an empty model and train it later.\n",
    "model = Doc2Vec(\n",
    "                # dm: training algorithm;\n",
    "                # 1: distributed memory/PV-DM;\n",
    "                # 0: distributed bag of words (PV-DBOW)\n",
    "                dm=1,\n",
    "                # vector_size: size of feature vectors\n",
    "                vector_size=300,\n",
    "                # window: max dist between current & predicted word\n",
    "                window=10,\n",
    "                # hs: 1: hierarchical softmax;\n",
    "                # hs: 0 : negative sampling if negative\n",
    "                hs=0,\n",
    "                # min_count: ignore words w/ lower frequency\n",
    "                # There is a risk to setting this too high\n",
    "                # particularly if a search term is likely unique,\n",
    "                # as it might be with a name. On the other hand,\n",
    "                # for such situations, a simple search might be better?\n",
    "                min_count=1,\n",
    "                # sample: randomly downsample hi-frequnecy words\n",
    "                # useful range: (0, 1e-5)\n",
    "                sample=1e-5,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "789a9795",
   "metadata": {},
   "source": [
    "The model is built around a vocabulary extracted from the training document corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b5d30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model vocabulary\n",
    "model.build_vocab(sample_docs_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2778c1e",
   "metadata": {},
   "source": [
    "We can now train the model (this may take some time for a large corpus):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03e9f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would be useful if we could display a progress bar for this...\n",
    "model.train(sample_docs_training,\n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=100, start_alpha=0.01, end_alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee55e1a0",
   "metadata": {},
   "source": [
    "Rather than creating a model each time we want to use it, we can save the model and then load it as required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "696a57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model\n",
    "model.save(\"lang_model.gensim\")\n",
    "\n",
    "# Load in a model\n",
    "model = Doc2Vec.load(\"lang_model.gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcde397",
   "metadata": {},
   "source": [
    "To retrieve a document matching a search phrase, we need to encode the search phrase and then try to find a matching document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10f677e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hansel',\n",
       " 'sister',\n",
       " 'cast',\n",
       " 'wicked',\n",
       " 'stepmother',\n",
       " 'went',\n",
       " 'forest',\n",
       " 'met',\n",
       " 'evil',\n",
       " 'witch']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrase = \"\"\"\n",
    "hansel and his sister were cast out by their wicked stepmother\n",
    "and went into forest and met an evil witch\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the search phrase\n",
    "tokens = clean_text(search_phrase)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab86cbd",
   "metadata": {},
   "source": [
    "Generate a vector for the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0643a17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the vector representation from the model\n",
    "search_vector = model.infer_vector(tokens, alpha=0.001, steps = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "671e4546",
   "metadata": {},
   "source": [
    "We can now search for related documents from the original training set based on how well their vectors match the vector generated for the search phrase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc6a7ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Yellow Fairy Book::How To Tell A True Princess', 0.530689537525177),\n",
       " ('The Yellow Fairy Book::In The Land Of Souls', 0.4511426091194153),\n",
       " ('The Lilac Fairy Book::The Raspberry Worm', 0.4241422712802887),\n",
       " ('The Lilac Fairy Book::Little Lasse', 0.41359323263168335),\n",
       " ('The Blue Fairy Book::Rumpelstiltzkin', 0.40738600492477417),\n",
       " ('The Olive Fairy Book::Kupti And Imani', 0.4026232659816742),\n",
       " ('The Yellow Fairy Book::A Story About A Darning-Needle',\n",
       "  0.40114545822143555),\n",
       " ('The Pink Fairy Book::The Shirt-Collar', 0.3960583806037903),\n",
       " ('The Lilac Fairy Book::A Fish Story', 0.38714125752449036),\n",
       " ('The Blue Fairy Book::Hansel And Grettel', 0.38626253604888916)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the top 5 matches\n",
    "matches = model.docvecs.most_similar([search_vector], topn=10)\n",
    "# To rank every document from the training corpus\n",
    "# set: topn=model.docvecs.count\n",
    "\n",
    "# The response gives the original training document ids and match scores\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd3ea3f",
   "metadata": {},
   "source": [
    "Let's try another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d088dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Blue Fairy Book::Cinderella, Or The Little Glass Slipper',\n",
       "  0.5241366624832153),\n",
       " ('The Blue Fairy Book::Rumpelstiltzkin', 0.5099612474441528),\n",
       " ('The Blue Fairy Book::Little Red Riding Hood', 0.4753239154815674),\n",
       " ('The Brown Fairy Book::Habogi', 0.47470545768737793),\n",
       " ('The Pink Fairy Book::Peter Bull', 0.4617704749107361),\n",
       " ('The Pink Fairy Book::The Merry Wives', 0.45907604694366455),\n",
       " ('The Crimson Fairy Book::Lovely Ilonka', 0.4566786587238312),\n",
       " ('The Yellow Fairy Book::The Swineherd', 0.4557437598705292),\n",
       " ('The Red Fairy Book::The Six Sillies', 0.4503322243690491),\n",
       " ('The Green Fairy Book::Spindle, Shuttle, And Needle', 0.4496467113494873)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrase = \"\"\"\n",
    "a poor orphan girl lives with her wicked stepmother and sisters\n",
    "but then her fairy godmother appears and she goes to a ball \n",
    "and leaves at midnight\n",
    "but loses her slipper then finally marries the prince\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the search phrase\n",
    "tokens = clean_text(search_phrase)\n",
    "search_vector = model.infer_vector(tokens, alpha=0.01, steps = 50)\n",
    "model.docvecs.most_similar([search_vector], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72af09b",
   "metadata": {},
   "source": [
    "Not that the result is stochastic (has a random element) in the way that the search vector is inferred: if you rerun the query, you will likely generate a different search vector. As a consequence, the search results returned are likely differ in their order and match scores each time the query is run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7680c5",
   "metadata": {},
   "source": [
    "## Creating a Search Tool\n",
    "\n",
    "The next step is to register a custom SQLite function that will generate a vector for a search term and return matching records on that basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abfbecdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtfunc import TableFunction\n",
    "\n",
    "class SQLite_doc2Vec_Search(TableFunction):\n",
    "    params = ['query', 'num', 'threshold']\n",
    "    columns = ['book', 'title', 'score']\n",
    "    name = 'doc2vec_model_search'\n",
    "    \n",
    "    model = Doc2Vec.load(\"lang_model.gensim\")\n",
    "    \n",
    "    def initialize(self, query=None, num=None, threshold=None):\n",
    "        num = 10 if num is None else num\n",
    "\n",
    "        tokens = clean_text(query)\n",
    "        search_vector = model.infer_vector(tokens, alpha=0.01, steps = 50)\n",
    "        scores = model.docvecs.most_similar([search_vector],\n",
    "                                            topn=model.docvecs.count)\n",
    "        if threshold:\n",
    "            scores = [(t, s) for (t, s) in scores if s >= threshold ]\n",
    "\n",
    "        self._iter = iter(scores)\n",
    " \n",
    "    def iterate(self, idx):\n",
    "        (tag, score) = next(self._iter)\n",
    "        items = tag.split(\"::\")\n",
    "        return (items[0], items[1], score,)\n",
    "\n",
    "# And register the function\n",
    "SQLite_doc2Vec_Search.register(db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e60639",
   "metadata": {},
   "source": [
    "The query searches over the model and can take various forms:\n",
    "\n",
    "- `doc2vec_model_search(\"search phrase\")`\n",
    "- `doc2vec_model_search(\"search phrase\", NUM_OF_RESULTS)`\n",
    "- `doc2vec_model_search(\"search phrase\", NUM_OF_RESULTS, MIN_SCORE)`\n",
    "- `doc2vec_model_search(\"search phrase\", NULL, MIN_SCORE)`\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2c9e3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Blue Fairy Book', 'Cinderella, Or The Little Glass Slipper', 0.505182147026062)\n",
      "('The Blue Fairy Book', 'Rumpelstiltzkin', 0.48724472522735596)\n",
      "('The Crimson Fairy Book', 'Lovely Ilonka', 0.47657108306884766)\n",
      "('The Green Fairy Book', 'Spindle, Shuttle, And Needle', 0.46215206384658813)\n",
      "('The Yellow Fairy Book', 'How To Tell A True Princess', 0.4570574462413788)\n",
      "('The Red Fairy Book', 'The Six Sillies', 0.45611968636512756)\n",
      "('The Brown Fairy Book', 'Habogi', 0.4532594382762909)\n"
     ]
    }
   ],
   "source": [
    "model_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM doc2vec_model_search('''{search_phrase}''', NULL, 0.45 );\n",
    "\"\"\"\n",
    "\n",
    "for i in db.execute(model_query):\n",
    "    print(i)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d73125a",
   "metadata": {},
   "source": [
    "## Saving Model Vectors into the Database\n",
    "\n",
    "If we look at the object type of one of the model vectors, we see that it is a `numpy.ndarray`, which can be easily represented as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bde00e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.docvecs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff56ea0",
   "metadata": {},
   "source": [
    "We can store this data in the SQLite database as a `BLOB`. To simplify the process of converting the array into and out of the appropriate format for storage in the database compared to its use as a gensim vector, we can register a custom handler for the `numpy.ndarray` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33b27ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Via https://stackoverflow.com/a/18622264/454773\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "def adapt_array(arr):\n",
    "    \"\"\"\n",
    "    http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "    \"\"\"\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(out.read())\n",
    "\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "\n",
    "# Converts np.array to TEXT when inserting\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "\n",
    "# Converts TEXT to np.array when selecting\n",
    "sqlite3.register_converter(\"array\", convert_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c8c10e",
   "metadata": {},
   "source": [
    "Now we need to reset the database to a connection that supports the custom handler we have just registered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fad5394e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the database connection to used the parsed datatype\n",
    "db.conn = sqlite3.connect(db_name, detect_types=sqlite3.PARSE_DECLTYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff71c330",
   "metadata": {},
   "source": [
    "We can now create a table with a custom \"array\" datatype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c6496a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x1278eaa40>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give ourselves a clean slate\n",
    "db[\"story_vectors\"].drop(ignore=True)\n",
    "\n",
    "\n",
    "# sqlite_utils doesn't appear to support custom types (yet?!)\n",
    "# The following errors on the \"array\" datatype\n",
    "\"\"\"\n",
    "db[\"story_vectors\"].create({\n",
    "    \"book\": str,\n",
    "    \"title\": str,\n",
    "    \"tag\": str, # a unique key derived from book and title\n",
    "    \"vector\": \"array\",\n",
    "}, pk=(\"book\", \"title\"),\n",
    "    # The following is not currently supported by sqlite_utils\n",
    "   #foreign_keys=[ ((\"book\", \"title\"), \"books\", (\"book\", \"title\"))] # local-table-id, foreign-table, foreign-table-id]\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# so we can create a table the old fashioned way...\n",
    "vector_table_create = \"\"\"\n",
    "CREATE TABLE story_vectors \n",
    "    (tag TEXT PRIMARY KEY, vector array, book TEXT, title TEXT );\n",
    "\"\"\"\n",
    "\n",
    "cur = db.conn.cursor()\n",
    "cur.execute(vector_table_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17401d6b",
   "metadata": {},
   "source": [
    "We can generate a list of dictionaries, one per record used to train the model, that can then be added directly to the `story_vectors` database table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9af598fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrecords = []\n",
    "\n",
    "for tag in model.docvecs.doctags:\n",
    "    xrecords.append({'book': tag.split('::')[0],\n",
    "                     'title': tag.split('::')[1],\n",
    "                     'tag': tag, 'vector':model.docvecs[tag]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e7001e",
   "metadata": {},
   "source": [
    "And add the records directly to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0345653",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table story_vectors (tag, vector, book, title)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"story_vectors\"].insert_all(xrecords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2cc41",
   "metadata": {},
   "source": [
    "Let's pull an example record back showing just the first few elements of the vector associated with the record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f15d8a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Blue Fairy Book::The Bronze Ring The Blue Fairy Book The Bronze Ring [ 2.321162    0.7221756  -0.6747307  -2.32237    -1.3788195   0.29455236\n",
      " -0.57455003  0.3207829   1.6113997  -2.4436612 ]\n"
     ]
    }
   ],
   "source": [
    "_q = f'SELECT * FROM story_vectors LIMIT 1;'\n",
    "\n",
    "for row in db.query(_q):\n",
    "    print(row['tag'], row['book'], row['title'], row['vector'][:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
