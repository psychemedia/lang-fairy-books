{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2943ee95",
   "metadata": {},
   "source": [
    "# Doc2Vec Searching of Lang Database\n",
    "\n",
    "Use `gensim` and a simple `doc2vec` model trained on stories from the Lang coloured fairy books to support semantic retrieval of fairy stories.\n",
    "\n",
    "The approach can be summarised as follows:\n",
    "\n",
    "- generate a vocabulary of terms representative of the search corpus;\n",
    "- generate a vector space where each dimension is a word in the vocabulary;\n",
    "- generate a vector for each document or search phrase;\n",
    "- retrieve documents based on similarity between document vector and search phrase vector.\n",
    "\n",
    "The following recipe is inspired by [How to make a search engine on Movies Description](https://github.com/ppontisso/Text-Search-Engine-using-Doc2Vec-and-TF-IDF/blob/master/notebook.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a356f87",
   "metadata": {},
   "source": [
    "## Connecting to the Database\n",
    "\n",
    "We're going to work with our Lang fairy story database, so let's set up a connection to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5a62edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite_utils import Database\n",
    "\n",
    "db_name = \"demo.db\"\n",
    "\n",
    "db = Database(db_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf9870",
   "metadata": {},
   "source": [
    "Let's remind ourselves of the database structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c8a8915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE [books] (\n",
      "   [book] TEXT,\n",
      "   [title] TEXT,\n",
      "   [text] TEXT,\n",
      "   [last_para] TEXT,\n",
      "   [first_line] TEXT,\n",
      "   [provenance] TEXT,\n",
      "   [chapter_order] INTEGER,\n",
      "   PRIMARY KEY ([book], [title])\n",
      ");\n",
      "CREATE TABLE [books_metadata] (\n",
      "   [title] TEXT,\n",
      "   [year] INTEGER\n",
      ");\n",
      "CREATE VIRTUAL TABLE [books_fts] USING FTS5 (\n",
      "    [title], [text],\n",
      "    content=[books]\n",
      ");\n",
      "CREATE TABLE 'books_fts_data'(id INTEGER PRIMARY KEY, block BLOB);\n",
      "CREATE TABLE 'books_fts_idx'(segid, term, pgno, PRIMARY KEY(segid, term)) WITHOUT ROWID;\n",
      "CREATE TABLE 'books_fts_docsize'(id INTEGER PRIMARY KEY, sz BLOB);\n",
      "CREATE TABLE 'books_fts_config'(k PRIMARY KEY, v) WITHOUT ROWID;\n",
      "CREATE TRIGGER [books_ai] AFTER INSERT ON [books] BEGIN\n",
      "  INSERT INTO [books_fts] (rowid, [title], [text]) VALUES (new.rowid, new.[title], new.[text]);\n",
      "END;\n",
      "CREATE TRIGGER [books_ad] AFTER DELETE ON [books] BEGIN\n",
      "  INSERT INTO [books_fts] ([books_fts], rowid, [title], [text]) VALUES('delete', old.rowid, old.[title], old.[text]);\n",
      "END;\n",
      "CREATE TRIGGER [books_au] AFTER UPDATE ON [books] BEGIN\n",
      "  INSERT INTO [books_fts] ([books_fts], rowid, [title], [text]) VALUES('delete', old.rowid, old.[title], old.[text]);\n",
      "  INSERT INTO [books_fts] (rowid, [title], [text]) VALUES (new.rowid, new.[title], new.[text]);\n",
      "END;\n",
      "CREATE TABLE story_vectors \n",
      "    (tag TEXT PRIMARY KEY, vector array, book TEXT, title TEXT );\n"
     ]
    }
   ],
   "source": [
    "print(db.schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685de298",
   "metadata": {},
   "source": [
    "Recall that we can perform a full text search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e445850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hansel And Grettel\n"
     ]
    }
   ],
   "source": [
    "#q = 'king \"three sons\" gold'\n",
    "q = 'hansel witch'\n",
    "_q = f'SELECT title FROM books_fts WHERE books_fts MATCH {db.quote(q)} ;'\n",
    "\n",
    "for row in db.query(_q):\n",
    "    print(row[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6e53e6",
   "metadata": {},
   "source": [
    "We can randomly sample a selection of rows with a query of the following form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3daa488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Fairy Nurse\n",
      "The Four Gifts\n",
      "The Hairy Man\n",
      "The Stone-Cutter\n",
      "The Little Soldier\n"
     ]
    }
   ],
   "source": [
    "# Via https://gist.github.com/alecco/9976dab8fda8256ed403054ed0a65d7b\n",
    "\n",
    "_q_random_sample = \"\"\"\n",
    "SELECT * FROM books\n",
    "WHERE rowid IN (SELECT rowid FROM books\n",
    "                WHERE title NOT LIKE \"Preface\"\n",
    "                ORDER BY random() LIMIT {});\n",
    "\"\"\"\n",
    "\n",
    "for row in db.query(_q_random_sample.format(5)):\n",
    "    print(row[\"title\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a90fb00",
   "metadata": {},
   "source": [
    "## Simple Model\n",
    "\n",
    "We could use an off-the-shelf model to process documents, or we can train our own model from our own documents so that the word vectors are aligned to our dataset. In a large corpus, we can train on a sample of documents if they are representative of the whole.\n",
    "\n",
    "If we train against the whole dataset, we can search into the dataset directly from the model. If train the model on a partial collection, then we can only compare search phrases and documents that we have generated vectors for.\n",
    "\n",
    "To create the model, it helps if we clean the documents, e.g. by decasing, and removing punctuation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b078532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import preprocess_string\n",
    "from gensim.parsing.preprocessing import strip_tags, strip_punctuation, strip_numeric, remove_stopwords\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Generate a cleaned, tokenised version of a text.\"\"\"\n",
    "    CUSTOM_FILTERS = [lambda x: x.lower(),\n",
    "                      strip_tags, strip_punctuation,\n",
    "                      strip_numeric, remove_stopwords]\n",
    "    \n",
    "    return preprocess_string(text, CUSTOM_FILTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f766568",
   "metadata": {},
   "source": [
    "Apply the cleaning function to the text on the way in to creating the training corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed577190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['time', 'certain', 'country', 'lived', 'king'],\n",
       " 'The Blue Fairy Book::The Bronze Ring',\n",
       " 'The Bronze Ring')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_corpus = db.query(_q_random_sample.format(9999))\n",
    "\n",
    "sample_docs = [(clean_text(r['text']),\n",
    "               f\"{r['book']}::{r['title']}\", #create a unique tag\n",
    "               r['title'])\n",
    "               for r in sample_corpus]\n",
    "\n",
    "# For the first doc, preview the first 5 cleaned words and title\n",
    "sample_docs[0][0][:5], sample_docs[0][1], sample_docs[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "422b938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The gensim model needs named tuples\n",
    "# including at least a words and tags dimension\n",
    "# Naively we can just use a document index count as the tag\n",
    "from collections import namedtuple\n",
    "\n",
    "StoryDoc = namedtuple('StoryDoc',\n",
    "                      'words tags title')\n",
    "\n",
    "sample_docs_training = []\n",
    "\n",
    "for i, sample_doc in enumerate(sample_docs):\n",
    "    sample_docs_training.append(StoryDoc(sample_doc[0],\n",
    "                                         [sample_doc[1]],\n",
    "                                         sample_doc[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad8fb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "\n",
    "# Define the parameters for building the model.\n",
    "# We can also pass a list of documents\n",
    "# via the first \"documents\" parameter\n",
    "# and the model will be trained against those.\n",
    "# Alternatively, create an empty model and train it later.\n",
    "model = Doc2Vec(\n",
    "                # dm: training algorithm;\n",
    "                # 1: distributed memory/PV-DM;\n",
    "                # 0: distributed bag of words (PV-DBOW)\n",
    "                dm=1,\n",
    "                # vector_size: size of feature vectors\n",
    "                vector_size=300,\n",
    "                # window: max dist between current & predicted word\n",
    "                window=10,\n",
    "                # hs: 1: hierarchical softmax;\n",
    "                # hs: 0 : negative sampling if negative\n",
    "                hs=0,\n",
    "                # min_count: ignore words w/ lower frequency\n",
    "                # There is a risk to setting this too high\n",
    "                # particularly if a search term is likely unique,\n",
    "                # as it might be with a name. On the other hand,\n",
    "                # for such situations, a simple search might be better?\n",
    "                min_count=1,\n",
    "                # sample: randomly downsample hi-frequency words\n",
    "                # useful range: (0, 1e-5)\n",
    "                sample=1e-5,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd47ecc",
   "metadata": {},
   "source": [
    "The model is built around a vocabulary extracted from the training document corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5735932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model vocabulary\n",
    "model.build_vocab(sample_docs_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05abf6f0",
   "metadata": {},
   "source": [
    "We can now train the model (this may take some time for a large corpus):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3834731d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It would be useful if we could display a progress bar for this\n",
    "model.train(sample_docs_training,\n",
    "            total_examples=model.corpus_count,\n",
    "            epochs=100, start_alpha=0.01, end_alpha=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d57f4b",
   "metadata": {},
   "source": [
    "Rather than creating a model each time we want to use it, we can save the model and then load it as required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "270d42aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save a model\n",
    "model.save(\"lang_model.gensim\")\n",
    "\n",
    "# Load in a model\n",
    "model = Doc2Vec.load(\"lang_model.gensim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b535998",
   "metadata": {},
   "source": [
    "To retrieve a document matching a search phrase, we need to encode the search phrase and then try to find a matching document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbf78375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hansel',\n",
       " 'sister',\n",
       " 'cast',\n",
       " 'wicked',\n",
       " 'stepmother',\n",
       " 'went',\n",
       " 'forest',\n",
       " 'met',\n",
       " 'evil',\n",
       " 'witch']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrase = \"\"\"\n",
    "hansel and his sister were cast out by their wicked stepmother\n",
    "and went into forest and met an evil witch\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the search phrase\n",
    "tokens = clean_text(search_phrase)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209f56e",
   "metadata": {},
   "source": [
    "Generate a vector for the tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95bcdebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the vector representation from the model\n",
    "search_vector = model.infer_vector(tokens, alpha=0.001, steps = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4de388a",
   "metadata": {},
   "source": [
    "We can now search for related documents from the original training set based on how well their vectors match the vector generated for the search phrase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dac949e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Blue Fairy Book::Hansel And Grettel', 0.7547191381454468),\n",
       " ('The Yellow Fairy Book::The Witch', 0.5689845085144043),\n",
       " ('The Red Fairy Book::The Three Dwarfs', 0.4800337553024292),\n",
       " ('The Red Fairy Book::Brother And Sister', 0.4466070830821991),\n",
       " ('The Yellow Fairy Book::The White Duck', 0.42747220396995544),\n",
       " ('The Red Fairy Book::Mother Holle', 0.4187214970588684),\n",
       " ('The Orange Fairy Book::The Two Caskets', 0.4114452302455902),\n",
       " ('The Red Fairy Book::The Twelve Brothers', 0.39679238200187683),\n",
       " ('The Orange Fairy Book::The Owl And The Eagle', 0.3924826979637146),\n",
       " ('The Yellow Fairy Book::The Nixy', 0.38102683424949646)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the top 10 matches\n",
    "matches = model.docvecs.most_similar([search_vector], topn=10)\n",
    "# To rank every document from the training corpus\n",
    "# set: topn=model.docvecs.count\n",
    "\n",
    "# The response gives the original training document ids and match scores\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f316a3",
   "metadata": {},
   "source": [
    "Let's try another one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "483abff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The Blue Fairy Book::Cinderella, Or The Little Glass Slipper',\n",
       "  0.5544741749763489),\n",
       " ('The Yellow Fairy Book::The Yellow Fairy Book', 0.5115742683410645),\n",
       " ('The Pink Fairy Book::Peter Bull', 0.5099089741706848),\n",
       " ('The Pink Fairy Book::The Merry Wives', 0.49374860525131226),\n",
       " ('The Green Fairy Book::Spindle, Shuttle, And Needle', 0.4853510856628418),\n",
       " ('The Blue Fairy Book::Rumpelstiltzkin', 0.46972209215164185),\n",
       " ('The Yellow Fairy Book::The Swineherd', 0.46485644578933716),\n",
       " ('The Yellow Fairy Book::How To Tell A True Princess', 0.46403932571411133),\n",
       " ('The Red Fairy Book::Mother Holle', 0.45142310857772827),\n",
       " ('The Blue Fairy Book::Little Red Riding Hood', 0.4508194923400879)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_phrase = \"\"\"\n",
    "a poor orphan girl lives with her wicked stepmother and sisters\n",
    "but then her fairy godmother appears and she goes to a ball \n",
    "and leaves at midnight\n",
    "but loses her slipper then finally marries the prince\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the search phrase\n",
    "tokens = clean_text(search_phrase)\n",
    "search_vector = model.infer_vector(tokens, alpha=0.01, steps = 50)\n",
    "model.docvecs.most_similar([search_vector], topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2320c227",
   "metadata": {},
   "source": [
    "Not that the result is stochastic (has a random element) in the way that the search vector is inferred: if you rerun the query, you will likely generate a different search vector. As a consequence, the search results returned are likely differ in their order and match scores each time the query is run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff800f4",
   "metadata": {},
   "source": [
    "## Creating a Search Tool\n",
    "\n",
    "The next step is to register a custom SQLite function that will generate a vector for a search term and return matching records on that basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12ac35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vtfunc import TableFunction\n",
    "\n",
    "class SQLite_doc2Vec_Model_Search(TableFunction):\n",
    "    params = ['query', 'threshold']\n",
    "    columns = ['book', 'title', 'score']\n",
    "    name = 'doc2vec_model_search'\n",
    "    \n",
    "    model = Doc2Vec.load(\"lang_model.gensim\")\n",
    "    \n",
    "    def initialize(self, query=None, num=None, threshold=None):\n",
    "        tokens = clean_text(query)\n",
    "        search_vector = model.infer_vector(tokens, alpha=0.01, steps = 50)\n",
    "        scores = model.docvecs.most_similar([search_vector],\n",
    "                                            topn=model.docvecs.count)\n",
    "        if threshold:\n",
    "            scores = [(t, s) for (t, s) in scores if s >= threshold ]\n",
    "\n",
    "        self._iter = iter(scores)\n",
    " \n",
    "    def iterate(self, idx):\n",
    "        (tag, score) = next(self._iter)\n",
    "        items = tag.split(\"::\")\n",
    "        return (items[0], items[1], score,)\n",
    "\n",
    "# And register the function\n",
    "SQLite_doc2Vec_Model_Search.register(db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a81968c",
   "metadata": {},
   "source": [
    "The query searches over the model and can take various forms:\n",
    "\n",
    "- `doc2vec_model_search(\"search phrase\")`\n",
    "- `doc2vec_model_search(\"search phrase\", MIN_SCORE)`\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9457177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The Blue Fairy Book', 'Cinderella, Or The Little Glass Slipper', 0.5492352247238159)\n",
      "('The Green Fairy Book', 'Spindle, Shuttle, And Needle', 0.5063244104385376)\n",
      "('The Yellow Fairy Book', 'The Yellow Fairy Book', 0.4934154152870178)\n",
      "('The Pink Fairy Book', 'Peter Bull', 0.48438823223114014)\n",
      "('The Violet Fairy Book', 'The Child Who Came From An Egg', 0.4662984609603882)\n",
      "('The Blue Fairy Book', 'Rumpelstiltzkin', 0.45463424921035767)\n",
      "('The Yellow Fairy Book', 'How To Tell A True Princess', 0.45086005330085754)\n"
     ]
    }
   ],
   "source": [
    "model_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM doc2vec_model_search('''{search_phrase}''', 0.45 );\n",
    "\"\"\"\n",
    "\n",
    "for i in db.execute(model_query):\n",
    "    print(i)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1be54",
   "metadata": {},
   "source": [
    "## Saving Model Vectors into the Database\n",
    "\n",
    "If we look at the object type of one of the model vectors, we see that it is a `numpy.ndarray`, which can be easily represented as a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d417a8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model.docvecs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4bbaf",
   "metadata": {},
   "source": [
    "We can store this data in the SQLite database as a `BLOB`. To simplify the process of converting the array into and out of the appropriate format for storage in the database compared to its use as a gensim vector, we can register a custom handler for the `numpy.ndarray` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a0d3c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Via https://stackoverflow.com/a/18622264/454773\n",
    "# See also: https://github.com/joosephook/sqlite3-numpy\n",
    "import sqlite3\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "def adapt_array(arr):\n",
    "    \"\"\"\n",
    "    http://stackoverflow.com/a/31312102/190597 (SoulNibbler)\n",
    "    \"\"\"\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(out.read())\n",
    "\n",
    "def convert_array(text):\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "\n",
    "# Converts np.array to TEXT when inserting\n",
    "sqlite3.register_adapter(np.ndarray, adapt_array)\n",
    "\n",
    "# Converts TEXT to np.array when selecting\n",
    "sqlite3.register_converter(\"array\", convert_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a66bf8",
   "metadata": {},
   "source": [
    "Now we need to reset the database to a connection that supports the custom handler we have just registered:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d699430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the database connection to used the parsed datatype\n",
    "db.conn = sqlite3.connect(db_name, detect_types=sqlite3.PARSE_DECLTYPES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "358c9d6e",
   "metadata": {},
   "source": [
    "We can now create a table with a custom \"array\" datatype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "298733e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x133501dc0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Give ourselves a clean slate\n",
    "db[\"story_vectors\"].drop(ignore=True)\n",
    "\n",
    "\n",
    "# sqlite_utils doesn't appear to support custom types (yet?!)\n",
    "# The following errors on the \"array\" datatype\n",
    "\"\"\"\n",
    "db[\"story_vectors\"].create({\n",
    "    \"book\": str,\n",
    "    \"title\": str,\n",
    "    \"tag\": str, # a unique key derived from book and title\n",
    "    \"vector\": \"array\",\n",
    "}, pk=(\"book\", \"title\"),\n",
    "    # The following is not currently supported by sqlite_utils\n",
    "   #foreign_keys=[ ((\"book\", \"title\"), \"books\", (\"book\", \"title\"))] # local-table-id, foreign-table, foreign-table-id]\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# so we can create a table the old fashioned way...\n",
    "vector_table_create = \"\"\"\n",
    "CREATE TABLE story_vectors \n",
    "    (tag TEXT PRIMARY KEY, vector array, book TEXT, title TEXT );\n",
    "\"\"\"\n",
    "\n",
    "cur = db.conn.cursor()\n",
    "cur.execute(vector_table_create)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a8fb78",
   "metadata": {},
   "source": [
    "We can generate a list of dictionaries, one per record used to train the model, that can then be added directly to the `story_vectors` database table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29e753f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xrecords = []\n",
    "\n",
    "for tag in model.docvecs.doctags:\n",
    "    xrecords.append({'book': tag.split('::')[0],\n",
    "                     'title': tag.split('::')[1],\n",
    "                     'tag': tag, 'vector':model.docvecs[tag]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e3b8c",
   "metadata": {},
   "source": [
    "And add the records directly to the database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31403946",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Table story_vectors (tag, vector, book, title)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[\"story_vectors\"].insert_all(xrecords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e84b638",
   "metadata": {},
   "source": [
    "Let's pull an example record back showing just the first few elements of the vector associated with the record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c0d28e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Blue Fairy Book::The Bronze Ring The Blue Fairy Book The Bronze Ring [-0.01405123 -0.50704396  0.7826763   0.6966156   0.87891227 -0.2688267\n",
      "  0.33178896 -1.6542805   1.053172    0.8667782 ]\n"
     ]
    }
   ],
   "source": [
    "_q = f'SELECT * FROM story_vectors LIMIT 1;'\n",
    "\n",
    "for row in db.query(_q):\n",
    "    print(row['tag'], row['book'], row['title'], row['vector'][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4f02e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>vector</th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Blue Fairy Book::The Bronze Ring</td>\n",
       "      <td>[-0.014051229, -0.50704396, 0.7826763, 0.69661...</td>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>The Bronze Ring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Blue Fairy Book::Prince Hyacinth And The D...</td>\n",
       "      <td>[0.22857311, -0.0002901034, 0.86985964, -0.280...</td>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Prince Hyacinth And The Dear Little Princess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Blue Fairy Book::East Of The Sun And West ...</td>\n",
       "      <td>[0.12482449, 0.509038, 0.730183, -1.0778545, 0...</td>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>East Of The Sun And West Of The Moon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tag  \\\n",
       "0               The Blue Fairy Book::The Bronze Ring   \n",
       "1  The Blue Fairy Book::Prince Hyacinth And The D...   \n",
       "2  The Blue Fairy Book::East Of The Sun And West ...   \n",
       "\n",
       "                                              vector                 book  \\\n",
       "0  [-0.014051229, -0.50704396, 0.7826763, 0.69661...  The Blue Fairy Book   \n",
       "1  [0.22857311, -0.0002901034, 0.86985964, -0.280...  The Blue Fairy Book   \n",
       "2  [0.12482449, 0.509038, 0.730183, -1.0778545, 0...  The Blue Fairy Book   \n",
       "\n",
       "                                          title  \n",
       "0                               The Bronze Ring  \n",
       "1  Prince Hyacinth And The Dear Little Princess  \n",
       "2          East Of The Sun And West Of The Moon  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "_q = f'SELECT * FROM story_vectors;'\n",
    "df = pd.read_sql(_q, db.conn)\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953175ee",
   "metadata": {},
   "source": [
    "We can get the cosine similarity for each row relative to a search vector using the `sklearn.metrics.pairwise.cosine_similarity` applied to a dataframe of vectors we want to match against.\n",
    "\n",
    "The `cosine_similarity()` function will happily accept two `pandas` dataframes, such as an N x M matrix of vectors we want to score against, and a 1 x M search vector matrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "34944b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>vector</th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Blue Fairy Book::Cinderella, Or The Little...</td>\n",
       "      <td>[1.1064563, 1.6556664, 0.65659255, 0.12633619,...</td>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Cinderella, Or The Little Glass Slipper</td>\n",
       "      <td>0.554474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>The Yellow Fairy Book::The Yellow Fairy Book</td>\n",
       "      <td>[0.2586239, 0.2307802, 0.54648733, -0.15965664...</td>\n",
       "      <td>The Yellow Fairy Book</td>\n",
       "      <td>The Yellow Fairy Book</td>\n",
       "      <td>0.511574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>The Pink Fairy Book::Peter Bull</td>\n",
       "      <td>[-1.1498377, 0.6431778, 0.94959325, 0.12849873...</td>\n",
       "      <td>The Pink Fairy Book</td>\n",
       "      <td>Peter Bull</td>\n",
       "      <td>0.509909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>The Pink Fairy Book::The Merry Wives</td>\n",
       "      <td>[-0.4850009, 1.2584103, 0.38522613, 0.6031495,...</td>\n",
       "      <td>The Pink Fairy Book</td>\n",
       "      <td>The Merry Wives</td>\n",
       "      <td>0.493749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>The Green Fairy Book::Spindle, Shuttle, And Ne...</td>\n",
       "      <td>[-0.0354758, 0.32155505, 0.37913308, -0.182975...</td>\n",
       "      <td>The Green Fairy Book</td>\n",
       "      <td>Spindle, Shuttle, And Needle</td>\n",
       "      <td>0.485351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tag  \\\n",
       "6    The Blue Fairy Book::Cinderella, Or The Little...   \n",
       "275       The Yellow Fairy Book::The Yellow Fairy Book   \n",
       "51                     The Pink Fairy Book::Peter Bull   \n",
       "71                The Pink Fairy Book::The Merry Wives   \n",
       "389  The Green Fairy Book::Spindle, Shuttle, And Ne...   \n",
       "\n",
       "                                                vector                   book  \\\n",
       "6    [1.1064563, 1.6556664, 0.65659255, 0.12633619,...    The Blue Fairy Book   \n",
       "275  [0.2586239, 0.2307802, 0.54648733, -0.15965664...  The Yellow Fairy Book   \n",
       "51   [-1.1498377, 0.6431778, 0.94959325, 0.12849873...    The Pink Fairy Book   \n",
       "71   [-0.4850009, 1.2584103, 0.38522613, 0.6031495,...    The Pink Fairy Book   \n",
       "389  [-0.0354758, 0.32155505, 0.37913308, -0.182975...   The Green Fairy Book   \n",
       "\n",
       "                                       title     score  \n",
       "6    Cinderella, Or The Little Glass Slipper  0.554474  \n",
       "275                    The Yellow Fairy Book  0.511574  \n",
       "51                                Peter Bull  0.509909  \n",
       "71                           The Merry Wives  0.493749  \n",
       "389             Spindle, Shuttle, And Needle  0.485351  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Grab the vectors and expand each on across columns\n",
    "match_vectors_df = df['vector'].apply(pd.Series)\n",
    "search_vector_df = pd.DataFrame(search_vector).T\n",
    "\n",
    "df['score'] = cosine_similarity(match_vectors_df,\n",
    "                                search_vector_df)\n",
    "\n",
    "df[df['score']>0.45].sort_values(\"score\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2b556a",
   "metadata": {},
   "source": [
    "So it's easy enough to create a custom function to search over the vectors table rather than the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "283cc9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQLite_doc2Vec_Table_Search(TableFunction):\n",
    "    params = ['query', 'threshold']\n",
    "    columns = ['book', 'title', 'score']\n",
    "    name = 'doc2vec_search'\n",
    "    \n",
    "    # If we move this into the body, we can update the database\n",
    "    # and respond to new rows added to story_vectors table\n",
    "    _q = f'SELECT book, title, vector FROM story_vectors;'\n",
    "    df = pd.read_sql(_q, db.conn)\n",
    "    match_vectors_df = df['vector'].apply(pd.Series)\n",
    "    \n",
    "    def initialize(self, query=None, threshold=None):\n",
    "        df = self.df\n",
    "        tokens = clean_text(query)\n",
    "        search_vector = model.infer_vector(tokens, alpha=0.01, steps = 50)\n",
    "\n",
    "        search_vector_df = pd.DataFrame(search_vector).T\n",
    "\n",
    "        # Find cosine similarity\n",
    "        df['score'] = cosine_similarity(self.match_vectors_df,\n",
    "                                        search_vector_df)\n",
    "        \n",
    "        # Apply minimum threshold if set\n",
    "        _iterator = df[df['score']>=threshold] if threshold else df\n",
    "\n",
    "        self._iter = _iterator[self.columns].itertuples(index=False,\n",
    "                                                        name=None)\n",
    " \n",
    "    def iterate(self, idx):\n",
    "        row = next(self._iter)\n",
    "        if row:\n",
    "            return (row[0],row[1], row[2],)\n",
    "\n",
    "# And register the function\n",
    "SQLite_doc2Vec_Table_Search.register(db.conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ea4fbc",
   "metadata": {},
   "source": [
    "Let's try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4498c05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Blue Fairy Book</td>\n",
       "      <td>Cinderella, Or The Little Glass Slipper</td>\n",
       "      <td>0.524345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Green Fairy Book</td>\n",
       "      <td>Spindle, Shuttle, And Needle</td>\n",
       "      <td>0.500835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Yellow Fairy Book</td>\n",
       "      <td>The Yellow Fairy Book</td>\n",
       "      <td>0.488937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    book                                    title     score\n",
       "0    The Blue Fairy Book  Cinderella, Or The Little Glass Slipper  0.524345\n",
       "1   The Green Fairy Book             Spindle, Shuttle, And Needle  0.500835\n",
       "2  The Yellow Fairy Book                    The Yellow Fairy Book  0.488937"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_query = f\"\"\"\n",
    "SELECT *\n",
    "FROM doc2vec_search('''{search_phrase}''')\n",
    "WHERE score>0.4 ORDER BY score DESC LIMIT 3;\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(vector_query, db.conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b54f404",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
